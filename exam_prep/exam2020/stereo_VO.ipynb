{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "\"\"\"\n",
    "Using the fact that we have two cameras:\n",
    "- Instead of triangulating new points in time, trinagulate new points in space: with a known baseline!\n",
    "\"\"\"\n",
    "\n",
    "# Params\n",
    "MATCH_NUM = 400\n",
    "IMG_PATH = '/exam_data/Question_32'\n",
    "K = np.array([[7.188560e+02, 0.000000e+00, 6.071928e+02], [0, 7.188560e+02, 1.852157e+02], [0, 0, 1]])\n",
    "BASELINE = 0.54\n",
    "SHOW_IMG = True\n",
    "# Specify img range(check dir)\n",
    "IMG_START = 400\n",
    "IMG_END = 451\n",
    "\n",
    "def extract_keypoints_sift(img1, img2, K, baseline):\n",
    "    \"\"\"\n",
    "    use sift to detect keypoint features\n",
    "    remember to include a Lowes ratio test\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    \n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    knn_matches = matcher.knnMatch(des1, des2, 2)\n",
    "    \n",
    "    \n",
    "    # Filter matches using the Lowe's ratio test\n",
    "    ratio_thresh = 0.7\n",
    "    good_matches = []\n",
    "    for m,n in knn_matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "            \n",
    "    good_matches = sorted(good_matches, key = lambda x:x.distance)\n",
    "    good_matches = good_matches[:MATCH_NUM]\n",
    "    \n",
    "    matchesTrainIdx = [x.trainIdx  for x in good_matches]\n",
    "    matchesQueryIdx = [x.queryIdx  for x in good_matches]\n",
    "   \n",
    "    match_points1 = [kp1[i].pt for i in matchesQueryIdx]\n",
    "    match_points2 = [kp2[i].pt for i in matchesTrainIdx]\n",
    "    \n",
    "    p1 = np.float32(np.array(match_points1))\n",
    "    p2 = np.float32(np.array(match_points2))\n",
    "\n",
    "    #project the feature points to 3D with triangulation\n",
    "    \n",
    "    M_left = K.dot(np.hstack((np.eye(3), np.zeros((3, 1)))))\n",
    "    M_rght = K.dot(np.hstack((np.eye(3), np.array([[-baseline, 0, 0]]).T)))\n",
    "\n",
    "    p1_flip = np.vstack((p1.T, np.ones((1, p1.shape[0]))))\n",
    "    p2_flip = np.vstack((p2.T, np.ones((1, p2.shape[0]))))\n",
    "\n",
    "    P = cv2.triangulatePoints(M_left, M_rght, p1_flip[:2], p2_flip[:2])\n",
    "\n",
    "    # Normalize homogeneous coordinates (P->Nx4  [N,4] is the normalizer/scale)\n",
    "    P = P / P[3]\n",
    "    land_points = P[:3]\n",
    "\n",
    "    return land_points.T, p1\n",
    "\n",
    "def featureTracking(prev_img, next_img, prev_points, world_points):\n",
    "    \"\"\"\n",
    "    Use OpenCV to find the prev_points from the prev_img in the next_img\n",
    "    Remember to remove points that could not be found from prev_points, next_points, and world_points\n",
    "    \"\"\"\n",
    "    params = dict(winSize=(21, 21),\n",
    "                 maxLevel=3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    \n",
    "    \n",
    "    next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_img, next_img, prev_points, nextPts=None, \\\n",
    "                                                      winSize=params[\"winSize\"], maxLevel=params[\"maxLevel\"], criteria=params[\"criteria\"])\n",
    "    \n",
    "    next_points = np.squeeze(next_points[np.where(status[:,0]==1),:])\n",
    "    prev_points = np.squeeze(prev_points[np.where(status[:,0]==1),:])\n",
    "    world_points = np.squeeze(world_points[np.where(status[:,0]==1),:])\n",
    "    \n",
    "    return world_points, prev_points, next_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: 1\n",
      "Position: [-0.01297325 -0.01542094  0.62708525]\n",
      "Rotation: [0.00310845 0.00040718 0.00175293]\n",
      "\n",
      "Image: 2\n",
      "Position: [-0.02365172 -0.02520789  1.22715597]\n",
      "Rotation: [ 0.00587283  0.00265582 -0.00024356]\n",
      "\n",
      "Image: 3\n",
      "Position: [-0.02442131 -0.03889883  1.79888507]\n",
      "Rotation: [ 0.00549912  0.00750156 -0.00615948]\n",
      "\n",
      "Image: 4\n",
      "Position: [-0.03383001 -0.05616668  2.34674669]\n",
      "Rotation: [ 0.00369323  0.01540971 -0.00968031]\n",
      "\n",
      "Image: 5\n",
      "Position: [-0.04888742 -0.06936477  2.8839128 ]\n",
      "Rotation: [ 5.77638179e-05  2.63217482e-02 -1.19463464e-02]\n",
      "\n",
      "Image: 6\n",
      "Position: [-0.08640851 -0.08093689  3.40569268]\n",
      "Rotation: [-0.00339436  0.04023305 -0.0122237 ]\n",
      "\n",
      "Image: 7\n",
      "Position: [-0.13193368 -0.09476621  3.909209  ]\n",
      "Rotation: [-0.00547124  0.05899114 -0.01226512]\n",
      "\n",
      "Image: 8\n",
      "Position: [-0.18555546 -0.10643544  4.41568118]\n",
      "Rotation: [-0.00412609  0.08089072 -0.01543517]\n",
      "\n",
      "Image: 9\n",
      "Position: [-0.26073303 -0.12065601  4.91680343]\n",
      "Rotation: [-0.00105586  0.10537448 -0.01260245]\n",
      "\n",
      "Image: 10\n",
      "Position: [-0.34648277 -0.13287262  5.40204388]\n",
      "Rotation: [ 0.00204105  0.13347362 -0.01228337]\n",
      "\n",
      "Image: 11\n",
      "Position: [-0.43977868 -0.14309424  5.87796095]\n",
      "Rotation: [ 0.00245435  0.16619918 -0.01367096]\n",
      "\n",
      "Image: 12\n",
      "Position: [-0.55955499 -0.16351522  6.3277929 ]\n",
      "Rotation: [-6.82074457e-06  2.02679129e-01 -1.01898547e-02]\n",
      "\n",
      "Image: 13\n",
      "Position: [-0.70476513 -0.17118737  6.76876784]\n",
      "Rotation: [-0.00408681  0.24367343 -0.00494198]\n",
      "\n",
      "Image: 14\n",
      "Position: [-0.85960751 -0.17977645  7.18949894]\n",
      "Rotation: [-7.10625256e-03  2.88561078e-01  1.52715502e-05]\n",
      "\n",
      "Image: 15\n",
      "Position: [-1.03905514 -0.18372651  7.60043229]\n",
      "Rotation: [-0.00826334  0.33622936  0.00609677]\n",
      "\n",
      "Image: 16\n",
      "Position: [-1.24696724 -0.18785717  7.99288037]\n",
      "Rotation: [-0.01084852  0.38652853  0.01736151]\n",
      "\n",
      "Image: 17\n",
      "Position: [-1.47956916 -0.19466794  8.36777256]\n",
      "Rotation: [-0.01358269  0.43942551  0.03201524]\n",
      "\n",
      "Image: 18\n",
      "Position: [-1.7261162  -0.18992876  8.722667  ]\n",
      "Rotation: [-0.01493351  0.49478711  0.04550211]\n",
      "\n",
      "Image: 19\n",
      "Position: [-1.99086076 -0.18748794  9.06233344]\n",
      "Rotation: [-0.01486732  0.5525245   0.05584938]\n",
      "\n",
      "Image: 20\n",
      "Position: [-2.26694213 -0.18266056  9.3846134 ]\n",
      "Rotation: [-0.01305024  0.61190114  0.06385468]\n",
      "\n",
      "Image: 21\n",
      "Position: [-2.5579638  -0.17126682  9.68869668]\n",
      "Rotation: [-0.00659909  0.67091551  0.07104668]\n",
      "\n",
      "Image: 22\n",
      "Position: [-2.87862304 -0.15491992  9.98916613]\n",
      "Rotation: [0.00411402 0.72862462 0.0808185 ]\n",
      "\n",
      "Image: 23\n",
      "Position: [-3.21220187 -0.14162706 10.26747935]\n",
      "Rotation: [0.01371423 0.78554144 0.09125478]\n",
      "\n",
      "Image: 24\n",
      "Position: [-3.5581641  -0.12235375 10.51497401]\n",
      "Rotation: [0.01956912 0.84200994 0.0997864 ]\n",
      "\n",
      "Image: 25\n",
      "Position: [-3.91066118 -0.11161474 10.7546548 ]\n",
      "Rotation: [0.0247126  0.89871535 0.10335891]\n",
      "\n",
      "Image: 26\n",
      "Position: [-4.2698885  -0.09731324 10.9573289 ]\n",
      "Rotation: [0.02910316 0.95567771 0.10566779]\n",
      "\n",
      "Image: 27\n",
      "Position: [-4.63429297 -0.06906635 11.13224464]\n",
      "Rotation: [0.03206665 1.01281477 0.10238845]\n",
      "\n",
      "Image: 28\n",
      "Position: [-5.00805646 -0.04080635 11.29785402]\n",
      "Rotation: [0.03389995 1.07107466 0.09506421]\n",
      "\n",
      "Image: 29\n",
      "Position: [-5.39582109e+00 -7.02366845e-03  1.14424411e+01]\n",
      "Rotation: [0.0344209  1.1296935  0.08633174]\n",
      "\n",
      "Image: 30\n",
      "Position: [-5.81151736  0.0234091  11.57292296]\n",
      "Rotation: [0.03329396 1.18759483 0.08156463]\n",
      "\n",
      "Image: 31\n",
      "Position: [-6.2451701   0.06418637 11.6816907 ]\n",
      "Rotation: [0.03150115 1.24169799 0.08086729]\n",
      "\n",
      "Image: 32\n",
      "Position: [-6.69157444  0.08522089 11.76304025]\n",
      "Rotation: [0.03262859 1.2925529  0.08222781]\n",
      "\n",
      "Image: 33\n",
      "Position: [-7.14273111  0.11242582 11.83476208]\n",
      "Rotation: [0.03564784 1.3402992  0.08230156]\n",
      "\n",
      "Image: 34\n",
      "Position: [-7.61733162  0.15330715 11.90038792]\n",
      "Rotation: [0.03599146 1.38439937 0.08125459]\n",
      "\n",
      "Image: 35\n",
      "Position: [-8.09163503  0.18398229 11.94134746]\n",
      "Rotation: [0.03644054 1.42519706 0.08044727]\n",
      "\n",
      "Image: 36\n",
      "Position: [-8.58710234  0.21783179 11.970134  ]\n",
      "Rotation: [0.03594663 1.460536   0.07957149]\n",
      "\n",
      "Image: 37\n",
      "Position: [-9.09835239  0.25938644 11.98892444]\n",
      "Rotation: [0.03269738 1.49032751 0.07874508]\n",
      "\n",
      "Image: 38\n",
      "Position: [-9.60562965  0.29356082 11.99227061]\n",
      "Rotation: [0.03075803 1.51578275 0.07760333]\n",
      "\n",
      "Image: 39\n",
      "Position: [-10.13783782   0.3312565   11.99546842]\n",
      "Rotation: [0.02875339 1.53866649 0.07806071]\n",
      "\n",
      "Image: 40\n",
      "Position: [-10.67839199   0.37075346  11.98444086]\n",
      "Rotation: [0.02553331 1.55746274 0.078607  ]\n",
      "\n",
      "Image: 41\n",
      "Position: [-11.23712822   0.40172501  11.97000083]\n",
      "Rotation: [0.02249778 1.57240927 0.080929  ]\n",
      "\n",
      "Image: 42\n",
      "Position: [-11.807212     0.43538399  11.95793005]\n",
      "Rotation: [0.01921845 1.58318467 0.08137816]\n",
      "\n",
      "Image: 43\n",
      "Position: [-12.38682197   0.47141704  11.94505072]\n",
      "Rotation: [0.01722044 1.58993738 0.08045265]\n",
      "\n",
      "Image: 44\n",
      "Position: [-12.98511931   0.50049981  11.92016783]\n",
      "Rotation: [0.01592321 1.59335291 0.08134861]\n",
      "\n",
      "Image: 45\n",
      "Position: [-13.60914493   0.53773107  11.8983596 ]\n",
      "Rotation: [0.0159561  1.59520909 0.08165702]\n",
      "\n",
      "Image: 46\n",
      "Position: [-14.25103884   0.57702973  11.87928141]\n",
      "Rotation: [0.01567084 1.59660209 0.0821264 ]\n",
      "\n",
      "Image: 47\n",
      "Position: [-14.91638439   0.61710337  11.86041422]\n",
      "Rotation: [0.0155019  1.59672406 0.08273934]\n",
      "\n",
      "Image: 48\n",
      "Position: [-15.60310232   0.65780535  11.84469555]\n",
      "Rotation: [0.01540671 1.59632314 0.08235215]\n",
      "\n",
      "Image: 49\n",
      "Position: [-16.30647593   0.69463024  11.81728091]\n",
      "Rotation: [0.01460852 1.59561282 0.07951973]\n",
      "\n",
      "Image: 50\n",
      "Position: [-17.03363845   0.73568462  11.79597911]\n",
      "Rotation: [0.01378604 1.59471674 0.07563567]\n",
      "\n",
      "\n",
      "======= Results ======= \n",
      "Position: [-17.03363845   0.73568462  11.79597911]\n",
      "Rotation: [0.01378604 1.59471674 0.07563567]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_left = glob.glob(\"exam_data\\\\Question_32\\\\left\\\\*.png\")\n",
    "images_right = glob.glob(\"exam_data\\\\Question_32\\\\right\\\\*.png\")\n",
    "# Get 3D points Using Triangulation\n",
    "left_img = cv2.imread(images_left[0])\n",
    "right_img = cv2.imread(images_right[0])\n",
    "landmark_3D, reference_2D = extract_keypoints_sift(left_img, right_img, K, BASELINE)\n",
    "\n",
    "# reference\n",
    "prev_img = left_img\n",
    "traj = np.zeros((left_img.shape[0]//2, 300, 3), dtype=np.uint8)\n",
    "# VO loop\n",
    "for i in range(1, len(images_left)):\n",
    "    curImage = cv2.imread(images_left[i])\n",
    "    curImage_R = cv2.imread(images_right[i])\n",
    "\n",
    "    # the 2D landmarks at the current time = t\n",
    "    landmark_3D, reference_2D, tracked_2Dpoints = featureTracking(prev_img, \n",
    "                                                                    curImage, \n",
    "                                                                    reference_2D,\n",
    "                                                                    landmark_3D)\n",
    "\n",
    "    #Calculate relative pose using PNP\n",
    "    _, rvec, tvec, _ = cv2.solvePnPRansac(landmark_3D,tracked_2Dpoints,K, None)\n",
    "\n",
    "    rot, _ = cv2.Rodrigues(rvec)\n",
    "    tvec = -rot.T.dot(tvec)  # coordinate transformation, from camera to world. What is the XYZ of the camera wrt World\n",
    "    inv_transform = np.hstack((rot.T, tvec))  # inverse transform. A tranform projecting points from the camera frame to the world frame\n",
    "\n",
    "    # re-obtain the 3D points\n",
    "    landmark_3D_new, reference_2D_new = extract_keypoints_sift(curImage, curImage_R, K, BASELINE)\n",
    "    \n",
    "    #Project the points from camera to world coordinates\n",
    "    reference_2D = reference_2D_new.astype('float32')\n",
    "    landmark_3D = inv_transform.dot(np.vstack((landmark_3D_new.T, np.ones((1, landmark_3D_new.shape[0])))))\n",
    "    landmark_3D = landmark_3D.T\n",
    "\n",
    "    prev_img = curImage\n",
    "\n",
    "    # draw images\n",
    "    draw_x, draw_y = int(tvec[0]) + 150, (left_img.shape[0]//2)-(int(tvec[2]) + 50);\n",
    "\n",
    "    print(f\"\\nImage: {i}\\nPosition: {tvec.squeeze()}\\nRotation: {rvec.squeeze()}\")\n",
    "    \n",
    "    if SHOW_IMG:\n",
    "        text = \"Coordinates:\\n x ={0:02f}m\\n y = {1:02f}m\\n z = {2:02f}m\".format(float(tvec[0]), float(tvec[1]),\n",
    "                                                                        float(tvec[2]))\n",
    "        text = text.split('\\n')\n",
    "        text_frame = np.zeros((left_img.shape[0]//2, 300, 3), dtype=np.uint8);\n",
    "        cv2.circle(traj, (draw_x, draw_y), 1, (0, 0, 255), 2)\n",
    "        cv2.putText(text_frame, text[0], (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "        cv2.putText(text_frame, text[1], (10, 60), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "        cv2.putText(text_frame, text[2], (10, 90), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "        cv2.putText(text_frame, text[3], (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "        \n",
    "        vis = np.vstack((text_frame, traj))\n",
    "        vis = np.hstack((curImage, vis))\n",
    "        \n",
    "        cv2.imshow(\"Trajectory\", vis)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27: break\n",
    "print(f\"\\n\\n======= Results ======= \\nPosition: {tvec.squeeze()}\\nRotation: {rvec.squeeze()}\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1902db9bb2e389c5c5f64e693209aef1412f369d132ca57a092e79ab8be655e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
