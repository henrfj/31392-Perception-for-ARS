{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic movie capture algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    cv2.imshow('image', frame)\n",
    "    cv2.waitKey(20)\n",
    "\n",
    "    \"\"\" Do your tracking here \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \"\"\" Draw the tracking onto the new image here\"\"\"\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # q will end the program\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse approach 1 - difference from frame 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "ret, frame = cap.read()\n",
    "firstFrame = None\n",
    "k = 0\n",
    "l = []\n",
    "frame_difference = 10\n",
    "while ret:\n",
    "    cv2.resize(frame,(50,30))\n",
    "\n",
    "    #Detecting movement\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    l.append(gray)\n",
    "    if firstFrame is None:\n",
    "        firstFrame = gray\n",
    "        continue\n",
    "    feat1 = cv2.goodFeaturesToTrack(gray, maxCorners=1000, qualityLevel=0.4, minDistance=10)\n",
    "    feat2, status, error = cv2.calcOpticalFlowPyrLK(gray, firstFrame, feat1, None)\n",
    "\n",
    "    for i in range(len(feat1)):\n",
    "        f10=int(feat1[i][0][0])\n",
    "        f11=int(feat1[i][0][1])\n",
    "        f20=int(feat2[i][0][0])\n",
    "        f21=int(feat2[i][0][1])\n",
    "\n",
    "        if np.sqrt((f20-f10)**2 + (f21-f11)**2) > frame_difference:\n",
    "            cv2.line(frame, (f10,f11), (f20, f21), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (f10, f11), 5, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow('image', frame)\n",
    "    cv2.waitKey\n",
    "    \n",
    "\n",
    "    if k>10:\n",
    "        firstFrame = l[-9]\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    k+=1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spare approach 2 - rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "ret, frame = cap.read()\n",
    "firstFrame = None\n",
    "while ret:\n",
    "\n",
    "    if firstFrame is None:\n",
    "        firstFrame = frame\n",
    "        continue\n",
    "    \n",
    "    diff = cv2.absdiff(frame,firstFrame)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)\n",
    "    diff_blur = cv2.GaussianBlur(diff_gray, (5,5), 0)\n",
    "\n",
    "    _, thresh_bin = cv2.threshold(diff_blur, 100, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh_bin,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    drawframe = frame.copy()\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 100:\n",
    "            cv2.rectangle(drawframe, (x, y), (x+w, y+h),(0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('image', drawframe)\n",
    "    cv2.waitKey\n",
    "    \n",
    "    firstFrame = frame\n",
    "    ret, frame = cap.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense approach - Chezch Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAADfklEQVR4nO3YsW1CUQxA0f+ijAB1/v6zwBDUyQ5OjyiCBLkSnFNaLlzdwmtmNgD+30d9AMC7EmCAiAADRAQYICLAABEBBoh83rN8OBxm3/cnnQLwms7n88/MHK/ndwV43/ftdDo97iqAN7DWutyae0EARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQWTPz9+W1vrdtuzzvHICX9DUzx+vhXQEG4HG8IAAiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiv24jG3fvmQi6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "height = 360\n",
    "width = 640\n",
    "cap.set(3, width)\n",
    "cap.set(4, height)\n",
    "download = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20.0, (width, height),1)\n",
    "\n",
    "ret, frame_new = cap.read()\n",
    "frame_new = cv2.resize(frame_new, (width, height), interpolation=cv2.INTER_AREA)\n",
    "frame_new = cv2.cvtColor(frame_new, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "while ret:\n",
    "    frame_old = frame_new\n",
    "    ret, frame_new = cap.read()\n",
    "    if not ret or (cv2.waitKey(1) & 0xFF == ord('q')): # Pressing q will end the program\n",
    "        break\n",
    "    frame_new = cv2.resize(frame_new, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    frame_new = cv2.cvtColor(frame_new, cv2.COLOR_BGR2RGB)\n",
    "    gray_old = cv2.cvtColor(frame_old, cv2.COLOR_RGB2GRAY)\n",
    "    gray_new = cv2.cvtColor(frame_new, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_old, gray_new, None, 0.5, 3, 15, 3, 5, 1.5, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1]) # Retrieving the magnitude and angle of every pixel\n",
    "\n",
    "    mask = np.zeros_like(frame_old) # Create empty matrix in dimesions as original image\n",
    "    mask[..., 1] = 255              # Set image saturation to maximum value as we do not need it\n",
    "    mask[..., 0] = ang*180/np.pi/2  # Set image hue according to the optical flow direction\n",
    "    mask[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) # Set image value according to the optical flow magnitude (normalized)\n",
    "    flow = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)       # Convert HSV to RGB (BGR) color representation\n",
    "    out = cv2.addWeighted(frame_old, 1, flow, 2, 0)    # Add images together\n",
    "    plt.xticks([]),plt.yticks([])                      # Turn off coord axis\n",
    "\n",
    "    cv2.imshow('image', out)\n",
    "    download.write(out)  # Video download\n",
    "    #cv2.waitKey(20)     # Wait for 20ms\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "download.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Robots.mp4')\n",
    "ret, frame_new = cap.read()\n",
    "\n",
    "robot_1 = cv2.imread('turtlebot.png')\n",
    "robot_1_gray = cv2.cvtColor(robot_1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "frame_old = None\n",
    "\n",
    "while ret:\n",
    "    if frame_old is None:\n",
    "        frame_old = frame_new\n",
    "        continue\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame_new, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ORB\n",
    "    # 1 \n",
    "    orb = cv2.ORB_create()\n",
    "    diff = cv2.absdiff(frame_new,frame_old)\n",
    "\n",
    "    kp, des = orb.detectAndCompute(diff, None) #Keypoints and descriptors\n",
    "\n",
    "    # 3\n",
    "    kp2, des2 = orb.detectAndCompute(robot_1_gray, None)\n",
    "\n",
    "    # 4 Match: brute force matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "    orb_matches = bf.match(des, des2)\n",
    "    orb_matches = sorted(orb_matches, key = lambda x:x.distance)\n",
    "\n",
    "    # Display matches\n",
    "    image = cv2.drawMatches(gray_frame,kp,robot_1_gray,kp2,orb_matches[:50],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imshow(\"image\", image)\n",
    "    #cv2.waitKey(20)\n",
    "\n",
    "    frame_old = frame_new\n",
    "    ret, frame_new = cap.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becc7bcbb7a4199260879ba1a9630da63d2f52d521041d6c190802a5dc80d452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
