{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of stereo camera\n",
    "\n",
    "Project Perception\n",
    "Task 1 \n",
    "As seen in week 4\n",
    "(Run with NONBASE Python 3.10 64-bit)\n",
    "- using Week 4 code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:\n",
    "- go into Running the code -> Parameters -> change what you need\n",
    "- Run all \n",
    "\n",
    "Changelog: \n",
    "- MM25.04.22: rewritten into jupyter & functions, corrected few bugs, changed to correct folder names\n",
    "\n",
    "Problems:\n",
    "- Rectification lookinÂ´ wanky\n",
    "- draw lines undone\n",
    "- tune parameters for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_undistortion = True\n",
    "rerun_rectification = False\n",
    "rerun_depth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectification function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    (r, c) = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "def epipolar_lines(gray_left, gray_right, debug):\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    kp_left, des_left = sift.detectAndCompute(gray_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(gray_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    # Get fundamental matrix\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC)\n",
    "\n",
    "    # Remove outliers\n",
    "    pts1 = pts1[mask.ravel() == 1]\n",
    "    pts2 = pts2[mask.ravel() == 1]\n",
    "\n",
    "    # Draw lines\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    epilines_left, keypoints_left = draw_lines(gray_left, gray_right, lines1, pts1, pts2)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    epilines_right, keypoints_right = draw_lines(\n",
    "        gray_right, gray_left, lines2, pts2, pts1)\n",
    "\n",
    "    if debug:\n",
    "        fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(10, 10))\n",
    "        axs[0, 0].imshow(keypoints_right)\n",
    "        axs[0, 0].set_title('left keypoints')\n",
    "        axs[0, 1].imshow(keypoints_left)\n",
    "        axs[0, 1].set_title('right keypoints')\n",
    "        axs[1, 0].imshow(epilines_left)\n",
    "        axs[1, 0].set_title('left epipolar lines')\n",
    "        axs[1, 1].imshow(epilines_right)\n",
    "        axs[1, 1].set_title('right epipolar lines')\n",
    "        plt.show()\n",
    "        \n",
    "    return F\n",
    "\n",
    "def rectify(img_left, img_right, debug=False):\n",
    "\n",
    "    # Change to grayscale\n",
    "    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "    F= epipolar_lines(gray_left, gray_right, debug)\n",
    "\n",
    "    # Find projection matrix\n",
    "    E = K_left.T@F@K_right\n",
    "    R_left, R_right, t = cv2.decomposeEssentialMat(E)\n",
    "    cv2.stereoRectify(K_left, dist_left, K_right,\n",
    "                        dist_right, img_left.shape[:2], R_left, t)\n",
    "    P_left = np.hstack((K_left@R_left, K_left@t))\n",
    "    P_right = np.hstack((K_right@R_right, K_right@t))\n",
    "\n",
    "    # Rectify images\n",
    "    (h,w,_) = img_left.shape\n",
    "    leftMapX, leftMapY = cv2.initUndistortRectifyMap(K_left, dist_left, R_left, P_left, (w, h), cv2.CV_32FC1)\n",
    "    left_rectified = cv2.remap(gray_left, leftMapX, leftMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "    rightMapX, rightMapY = cv2.initUndistortRectifyMap(K_right, dist_right, R_right, P_right, (w, h), cv2.CV_32FC1)\n",
    "    right_rectified = cv2.remap(gray_right, rightMapX, rightMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    return left_rectified, right_rectified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectification done\n"
     ]
    }
   ],
   "source": [
    "if rerun_rectification:\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob('stereo_calibration/left-*.png')\n",
    "    imagesR = glob.glob('stereo_calibration/right-*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Create a sift detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    i = 0\n",
    "    for i in range(0, len(imagesL)):\n",
    "        img_left = cv2.imread(imagesL[i])\n",
    "        img_right = cv2.imread(imagesR[i])\n",
    "        left_rectified, right_rectified = rectify(img_left, img_right, debug=False) \n",
    "        epipolar_lines(left_rectified,right_rectified, debug=False)\n",
    "\n",
    "        # Save images into folder\n",
    "        cv2.imwrite('rectified/left-'+str(i)+'.png', left_rectified)\n",
    "        cv2.imwrite('rectified/right-'+str(i)+'.png', right_rectified)\n",
    "        i += 1\n",
    "\n",
    "print(\"Rectification done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDISTORTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lukman upraven na zadani slozky \n",
    "def undistort_img(side):\n",
    "    # Implement the number of vertical and horizontal corners\n",
    "    nb_vertical = 9\n",
    "    nb_horizontal = 6\n",
    "\n",
    "    if side == 'left':\n",
    "        path_in = 'rectified/left-*.png'\n",
    "        path_out = 'rectified-undistorted/left-'\n",
    "    elif side == 'right':\n",
    "        path_in = 'rectified/right-*.png'\n",
    "        path_out = 'rectified-undistorted/right-'\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nb_horizontal*nb_vertical, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nb_vertical, 0:nb_horizontal].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints_left = []  # 2d points in image plane.\n",
    "\n",
    "    images = glob.glob(path_in)\n",
    "    assert images\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Implement findChessboardCorners here\n",
    "        ret, corners = cv2.findChessboardCorners(\n",
    "            gray, (nb_vertical, nb_horizontal))\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints_left.append(corners)\n",
    "\n",
    "    # get the camera matrix\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints_left, gray.shape[::-1], None, None)\n",
    "    # just to get dimensions, should be same for all images to come\n",
    "    get_dim = cv2.imread('stereo_calibration/left-0000.png')\n",
    "    h,  w = get_dim.shape[:2]\n",
    "    K, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 0)\n",
    "\n",
    "    # save images into folder\n",
    "    i = 0\n",
    "    for fname in images:\n",
    "        # undistort\n",
    "        img = cv2.imread(fname)\n",
    "        dst = cv2.undistort(img, mtx, dist, None, K)\n",
    "\n",
    "        # crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "        # save image\n",
    "        cv2.imwrite(path_out+str(i)+'.png', dst)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Undistortion \"+side+ \" done\")\n",
    "    return K, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undistortion left done\n",
      "Undistortion right done\n"
     ]
    }
   ],
   "source": [
    "#values from previous runs. Used rerun is set to false (needed in the next part)\n",
    "K_left = np.array([[590.24505615, 0, 723.85543853], [\n",
    "                  0, 700.56091309, 369.43859036], [0, 0, 1]])\n",
    "K_right = np.array([[698.72259521, 0, 648.50704794], [\n",
    "                   0, 698.6318967, 374.0875587], [0, 0, 1]])\n",
    "dist_right = np.array([[-3.29479763e-01, 1.41779367e-01, -\n",
    "                      1.15867147e-04, 2.53566722e-04, -3.10092346e-02]])\n",
    "dist_left = np.array([[-3.25580109e-01, 1.39151479e-01, -\n",
    "                     2.55229666e-04, 4.20203965e-04, -3.19659112e-02]])\n",
    "\n",
    "if rerun_undistortion:\n",
    "    K_left, dist_left = undistort_img(side='left')\n",
    "    K_right, dist_right = undistort_img(side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map():\n",
    "     # Read the rectified images\n",
    "    imagesL = glob.glob('rectified/left*.png')\n",
    "    imagesR = glob.glob('rectified/right*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    for i in range(0, len(imagesL)):\n",
    "        img_left = cv2.imread(imagesL[i])\n",
    "        img_right = cv2.imread(imagesR[i])\n",
    "        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        min_disp = 5  # 7\n",
    "        num_disp = 16  # 3*16\n",
    "        block_size = 5  # 5, 11\n",
    "        stereo = cv2.StereoBM_create(\n",
    "            numDisparities=num_disp, blockSize=block_size)\n",
    "        stereo.setMinDisparity(min_disp)\n",
    "        stereo.setDisp12MaxDiff(200)  # 200\n",
    "        stereo.setUniquenessRatio(1)  # 1\n",
    "        stereo.setSpeckleRange(10)  # 3\n",
    "        stereo.setSpeckleWindowSize(1)  # 3\n",
    "        disp = stereo.compute(gray_left, gray_right).astype(np.float32) / 16.0\n",
    "\n",
    "        if debug:\n",
    "            f, (ax_left, ax_middle, ax_right) = plt.subplots(1, 3, figsize=(18, 18))\n",
    "            ax_left.imshow(gray_left)\n",
    "            ax_middle.imshow(gray_right)\n",
    "            ax_right.imshow(disp)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'debug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukas\\OneDrive - ÄeskÃ© vysokÃ© uÄenÃ­ technickÃ© v Praze\\Zaloha\\Lukas\\DTU\\Perception for Autonomous Systems\\Exercises\\Henrik\\31392-Perception-for-ARS\\Final project\\calibration\\Calibration_mik.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000018?line=0'>1</a>\u001b[0m depth_map() \u001b[39mif\u001b[39;00m rerun_depth \u001b[39melse\u001b[39;00m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDepth not run\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Lukas\\OneDrive - ÄeskÃ© vysokÃ© uÄenÃ­ technickÃ© v Praze\\Zaloha\\Lukas\\DTU\\Perception for Autonomous Systems\\Exercises\\Henrik\\31392-Perception-for-ARS\\Final project\\calibration\\Calibration_mik.ipynb Cell 17'\u001b[0m in \u001b[0;36mdepth_map\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000016?line=22'>23</a>\u001b[0m stereo\u001b[39m.\u001b[39msetSpeckleWindowSize(\u001b[39m1\u001b[39m)  \u001b[39m# 3\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000016?line=23'>24</a>\u001b[0m disp \u001b[39m=\u001b[39m stereo\u001b[39m.\u001b[39mcompute(gray_left, gray_right)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m16.0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000016?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m debug:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000016?line=26'>27</a>\u001b[0m     f, (ax_left, ax_middle, ax_right) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m18\u001b[39m, \u001b[39m18\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/OneDrive%20-%20%C4%8Cesk%C3%A9%20vysok%C3%A9%20u%C4%8Den%C3%AD%20technick%C3%A9%20v%20Praze/Zaloha/Lukas/DTU/Perception%20for%20Autonomous%20Systems/Exercises/Henrik/31392-Perception-for-ARS/Final%20project/calibration/Calibration_mik.ipynb#ch0000016?line=27'>28</a>\u001b[0m     ax_left\u001b[39m.\u001b[39mimshow(gray_left)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'debug' is not defined"
     ]
    }
   ],
   "source": [
    "depth_map() if rerun_depth else print(\"Depth not run\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b633d7eae87b5fed5bf766898b0c683375244dd1706eb915bb836f7448798b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
