{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different methods from week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_keypoints_SIFT(img1, img2):\n",
    "    \"\"\"\n",
    "    use SIFT to detect keypoint features and match between images.\n",
    "    Includes a Lowes ratio test to improve performance.\n",
    "\n",
    "    params:\n",
    "        - img1, img2: images to match.\n",
    "        - K: projection matrices for images\n",
    "        - baseline: base translation between cameras.\n",
    "\n",
    "    returns:\n",
    "        - initial landmark points.\n",
    "        - corresponding 2D points in img1.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1 SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # 2 KNN match with two (best and second best)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # 3 Ratio test!\n",
    "    kp1_indexes = []\n",
    "    kp2_indexes = []\n",
    "    good_matches= []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.70*n.distance:\n",
    "            good_matches.append([m])\n",
    "            kp1_indexes.append(m.queryIdx)\n",
    "            kp2_indexes.append(m.trainIdx)\n",
    "\n",
    "    ## 4 extract the keypoints of the \"good\" matches\n",
    "    kp1 = np.asarray(kp1)\n",
    "    kp2 = np.asarray(kp2)\n",
    "    match_points1 = [p.pt for p in kp1[kp1_indexes]]\n",
    "    match_points2 = [p.pt for p in kp2[kp2_indexes]]\n",
    "\n",
    "    p1 = np.array(match_points1).astype(np.float32)\n",
    "    p2 = np.array(match_points2).astype(np.float32)\n",
    "\n",
    "    return p1, p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - spare optical matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"video/sample/left/*.png\")\n",
    "no_of_frames = len(images)-1\n",
    "\n",
    "\n",
    "image_buffer = [] # Sliding image buffer\n",
    "buffer_len = 10\n",
    "q = 0 # Queue index\n",
    "frame_difference = 15\n",
    "max_frame_dist = 70\n",
    "\n",
    "# Get frame\n",
    "compare_frame = cv2.imread(images[1])\n",
    "gray_compare = cv2.cvtColor(compare_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "buffer = []\n",
    "\n",
    "for k in range(1, no_of_frames, 1):\n",
    "    # Get frame\n",
    "    frame = cv2.imread(images[k])\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    buffer.append(gray)\n",
    "\n",
    "    # Extract and track features\n",
    "    feat1 = cv2.goodFeaturesToTrack(gray, maxCorners=10000, qualityLevel=0.001, minDistance=10)\n",
    "    feat2, status, error = cv2.calcOpticalFlowPyrLK(gray, gray_compare, feat1, None)\n",
    "    # Remove untracked features    \n",
    "    good_indexes = np.where(np.any(status==1, axis=1))[0]\n",
    "    feat1 = feat1[good_indexes]\n",
    "    feat2 = feat2[good_indexes]\n",
    "    # Draw the best features\n",
    "    for i in range(len(feat1)):\n",
    "        f10=int(feat1[i][0][0])\n",
    "        f11=int(feat1[i][0][1])\n",
    "        f20=int(feat2[i][0][0])\n",
    "        f21=int(feat2[i][0][1])\n",
    "        x = (f20-f10)\n",
    "        y = (f21-f11)\n",
    "        distance = np.sqrt(x**2 + y**2)\n",
    "        if max_frame_dist > distance  and distance > frame_difference:\n",
    "            if y==0:\n",
    "                continue\n",
    "            angle = np.arctan(x/y)\n",
    "            if angle<0:\n",
    "                cv2.line(frame, (f10,f11), (f20, f21), (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (f10, f11), 5, (0, 255, 0), -1)\n",
    "\n",
    "    if k%10==0:\n",
    "        gray_compare = buffer[-9].copy()\n",
    "\n",
    "    cv2.imshow('image', frame)\n",
    "    cv2.waitKey\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becc7bcbb7a4199260879ba1a9630da63d2f52d521041d6c190802a5dc80d452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
