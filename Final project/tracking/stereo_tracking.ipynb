{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without occlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path in .gitignore for sample without occlusions is in tracking/conveyor_sample_without \n",
    "and \n",
    "\n",
    "can be downloaded \n",
    "<a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2Fsample%5FStereo%5Fconveyor%5Fwithout%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>\n",
    "\n",
    "The whole conveyor belt dataset without occlusions downloaded <a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2FStereo%5Fconveyor%5Fwithout%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>\n",
    "\n",
    "Dataset conveyor with occlusions can be downloaded <a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2FStereo%5Fconveyor%5Fwith%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First IÂ´ll try sparse optical flow from Week 2. I will track where the object is and then use the depth map from previous task to aquire the depth = Z coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#show in popup\n",
    "# %matplotlib qt\n",
    "#show inlince\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "def optical_flow(path, show_windows=True, no_of_frames=0, resize=False, scale=1, display_OF=False):\n",
    "    \"\"\" sensitivity in pixels to discard noise\"\"\"\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "\n",
    "\n",
    "    images = glob.glob(path)\n",
    "    assert images != [], \"No images found in {}\".format(path)\n",
    "    \n",
    "    first_frame = cv2.imread(images[0])\n",
    "    if resize: first_frame = cv2.resize(first_frame, (0, 0), fx=scale, fy=scale)\n",
    "    print(\"Dimensions:\", first_frame.shape, \"\\n\")\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    mask[..., 1] = 255\n",
    "\n",
    "    #write if else statement on one line\n",
    "    \n",
    "    if no_of_frames == 0:   no_of_frames = len(images)-1\n",
    "    esle:                   no_of_frames = no_of_frames\n",
    "\n",
    "    for i in range(1, no_of_frames):\n",
    "        if i == 1:  prev_frame = first_frame #for displaying only\n",
    "        else:   \n",
    "            prev_frame = cv2.imread(images[i-1])\n",
    "            if resize: prev_frame = cv2.resize(prev_frame, (0,0), fx=scale, fy=scale)\n",
    "\n",
    "        next_frame = cv2.imread(images[i])\n",
    "        if resize: next_frame = cv2.resize(next_frame, (0,0), fx=scale, fy=scale)\n",
    "        next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0) #calculate dence OF\n",
    "\n",
    "        if display_OF:\n",
    "            mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1]) # Retrieving the magnitude and angle of every pixel\n",
    "            mask = np.zeros_like(prev_frame) # Create empty matrix in dimesions as original image\n",
    "            mask[..., 1] = 255              # Set image saturation to maximum value as we do not need it\n",
    "            mask[..., 0] = ang*180/np.pi/2  # Set image hue according to the optical flow direction\n",
    "            mask[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        h, w = flow.shape[:2]\n",
    "        fx, fy = flow[:,:,0], flow[:,:,1]\n",
    "        ang = np.arctan2(fy, fx) + np.pi\n",
    "        v = np.sqrt(fx*fx+fy*fy)\n",
    "\n",
    "        hsv = np.zeros((h, w, 3), np.uint8)\n",
    "        hsv[...,0] = ang*(90/np.pi/2)\n",
    "        hsv[...,1] = 255\n",
    "        hsv[...,2] = np.minimum(v*4, 255)\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        gray1 = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray1, 3 , 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "        cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # loop over the contours\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            centroid = (cx,cy)\n",
    "            area = cv2.contourArea(c)\n",
    "            #print area\n",
    "\n",
    "            areaTH = 5000\n",
    "            if resize: areaTH = areaTH*scale**2\n",
    "\n",
    "            # if the contour is too small, ignore it\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            a = x + w\n",
    "            b = y + h\n",
    "            #display text in the window centroid\n",
    "            if area > areaTH:\n",
    "                cv2.putText(next_frame, \"Area: {}\".format(area), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                cv2.putText(next_frame, \"Centroid: ({}, {})\".format(cx, cy), (x, y+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                cv2.putText(next_frame, \"Height: {}\".format(h), (x, y+40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                cv2.putText(next_frame, \"Width: {}\".format(w), (x, y+60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                cv2.rectangle(next_frame, (x, y), (a , b ), (0, 255, 0), 2)\n",
    "                cv2.circle(next_frame,(cx,cy),5,(0,0,255), -1)\n",
    "\n",
    "                # For kalman\n",
    "                xs.append(cx)\n",
    "                ys.append(cy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            # if (area > areaTH) and (area < areaTH2) and (w < 400) and (h < 600) :\n",
    "        \n",
    "        \n",
    "        if display_OF:  flow = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR) #convert to RGB for display\n",
    "        if show_windows: \n",
    "            if display_OF:  out = cv2.addWeighted(next_frame, 1, flow, 2, 0)\n",
    "            else:           out = next_frame\n",
    "            cv2.imshow('frame', out)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): #stop on q\n",
    "            break\n",
    "        prev_gray = next_gray #update from previous frame\n",
    "        print(\"\\rFrame {}/{}\".format(i, no_of_frames+1), end=\"\")\n",
    "\n",
    "    cv2.destroyAllWindows() #close all windows\n",
    "    \n",
    "\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (720, 1280, 3) \n",
      "\n",
      "Frame 128/130"
     ]
    }
   ],
   "source": [
    "#PARAMETERS\n",
    "display = True  #whether to display the windows\n",
    "# path_OF = \"conveyor_sample_without/left/*.png\"    #sample video without occlusions\n",
    "path_OF = \"video/sample/left/*.png\"        #Full video without occlusions\n",
    "# path_OF = \"conveyor_full_with/left/*.png\"         #full video with occlusions\n",
    "\n",
    "display_OF = True   #whether to display the optical flow\n",
    "no_of_frames = 0    #how many images to use. Use 0 for all\n",
    "resize = False       #resize for quicker run. BE CAREFUL! Cant use resizing for depth, also OF is not accurate\n",
    "scale = 1         #resize by this factor \n",
    "xs, ys = optical_flow(path=path_OF, show_windows=display, no_of_frames=no_of_frames, \n",
    "            resize=resize, scale=scale, display_OF=display_OF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9a4ba7a39ad5692da286452aea182a2f639774b342ad6371c4f013f8b98072d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
