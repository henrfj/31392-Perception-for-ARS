{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> 6cc8745b1ee30cbcf8d5d9cef0a011acd7749d70
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 574\n",
      "y 620\n",
      "x 571\n",
      "y 0\n",
      "x 806\n",
      "y 184\n",
      "x 44\n",
      "y 227\n",
      "{3: (294, 473)}\n",
      "x 44\n",
      "y 227\n",
      "x 45\n",
      "y 238\n",
      "x 164\n",
      "y 299\n",
      "x 795\n",
      "y 432\n",
      "{6: (921, 499)}\n",
      "x 795\n",
      "y 432\n",
      "{6: (921, 500)}\n",
      "x 796\n",
      "y 434\n",
      "{6: (925, 497)}\n",
      "x 795\n",
      "y 427\n",
      "{6: (928, 496)}\n",
      "x 794\n",
      "y 426\n",
      "{6: (928, 497)}\n",
      "x 794\n",
      "y 426\n",
      "{6: (929, 497)}\n",
      "x 794\n",
      "y 426\n",
      "{6: (929, 496)}\n",
      "x 794\n",
      "y 425\n",
      "{6: (929, 496)}\n",
      "x 795\n",
      "y 426\n",
      "{6: (932, 494)}\n",
      "x 801\n",
      "y 426\n",
      "x 912\n",
      "y 411\n",
      "{7: (978, 463)}\n",
      "x 912\n",
      "y 415\n",
      "x 1216\n",
      "y 525\n",
      "{8: (1247, 578)}\n",
      "x 1215\n",
      "y 520\n",
      "{8: (1246, 575)}\n",
      "x 1212\n",
      "y 514\n",
      "{8: (1244, 572)}\n",
      "x 1209\n",
      "y 509\n",
      "{8: (1230, 585)}\n",
      "x 1180\n",
      "y 509\n",
      "{8: (1231, 582)}\n",
      "x 1182\n",
      "y 509\n",
      "{8: (1224, 583)}\n",
      "x 1169\n",
      "y 505\n",
      "{8: (1209, 588)}\n",
      "x 1139\n",
      "y 508\n",
      "{8: (1209, 585)}\n",
      "x 1139\n",
      "y 507\n",
      "{8: (1206, 581)}\n",
      "x 1132\n",
      "y 498\n",
      "{8: (1198, 567)}\n",
      "x 1116\n",
      "y 483\n",
      "x 1081\n",
      "y 462\n",
      "{9: (1164, 535)}\n",
      "x 1063\n",
      "y 447\n",
      "{9: (1162, 522)}\n",
      "x 1058\n",
      "y 429\n",
      "{9: (1162, 510)}\n",
      "x 1058\n",
      "y 413\n",
      "{9: (1161, 502)}\n",
      "x 1057\n",
      "y 404\n",
      "{9: (1161, 487)}\n",
      "x 1057\n",
      "y 380\n",
      "{9: (1161, 490)}\n",
      "x 1058\n",
      "y 376\n",
      "x 974\n",
      "y 264\n",
      "{10: (1133, 410)}\n",
      "x 986\n",
      "y 261\n",
      "{10: (1142, 387)}\n",
      "x 1005\n",
      "y 258\n",
      "{10: (1142, 373)}\n",
      "x 1005\n",
      "y 255\n",
      "{10: (1141, 363)}\n",
      "x 1003\n",
      "y 251\n",
      "{10: (1127, 357)}\n",
      "x 974\n",
      "y 248\n",
      "{10: (1143, 349)}\n",
      "x 1006\n",
      "y 249\n",
      "{10: (1143, 348)}\n",
      "x 1006\n",
      "y 249\n",
      "{10: (1162, 333)}\n",
      "x 1044\n",
      "y 249\n",
      "{10: (1159, 329)}\n",
      "x 1038\n",
      "y 254\n",
      "{10: (1158, 319)}\n",
      "x 1036\n",
      "y 253\n",
      "{10: (1157, 309)}\n",
      "x 1034\n",
      "y 253\n",
      "{10: (1156, 303)}\n",
      "x 1032\n",
      "y 248\n",
      "{10: (1155, 304)}\n",
      "x 1030\n",
      "y 245\n",
      "{10: (1154, 306)}\n",
      "x 1028\n",
      "y 249\n",
      "{10: (1153, 314)}\n",
      "x 1026\n",
      "y 263\n",
      "{10: (1153, 323)}\n",
      "x 1026\n",
      "y 264\n",
      "{10: (1151, 333)}\n",
      "x 1023\n",
      "y 265\n",
      "x 1021\n",
      "y 266\n",
      "{11: (1080, 315)}\n",
      "x 1019\n",
      "y 266\n",
      "{11: (1078, 315)}\n",
      "x 1016\n",
      "y 266\n",
      "{11: (1078, 315)}\n",
      "x 1016\n",
      "y 266\n",
      "{11: (1075, 321)}\n",
      "x 1013\n",
      "y 267\n",
      "{11: (1074, 322)}\n",
      "x 1010\n",
      "y 268\n",
      "{11: (1073, 323)}\n",
      "x 1010\n",
      "y 268\n",
      "{11: (1069, 323)}\n",
      "x 1004\n",
      "y 268\n",
      "{11: (1067, 325)}\n",
      "x 1002\n",
      "y 270\n",
      "{11: (1068, 327)}\n",
      "x 1004\n",
      "y 270\n",
      "{11: (1065, 338)}\n",
      "x 1002\n",
      "y 270\n",
      "{11: (1062, 338)}\n",
      "x 999\n",
      "y 270\n",
      "{11: (1060, 339)}\n",
      "x 996\n",
      "y 272\n",
      "{11: (1059, 330)}\n",
      "x 994\n",
      "y 272\n",
      "{11: (1057, 330)}\n",
      "x 992\n",
      "y 272\n",
      "{11: (1055, 330)}\n",
      "x 990\n",
      "y 272\n",
      "{11: (1053, 330)}\n",
      "x 988\n",
      "y 273\n",
      "{11: (1052, 331)}\n",
      "x 986\n",
      "y 274\n",
      "{11: (1050, 331)}\n",
      "x 984\n",
      "y 274\n",
      "{11: (1048, 331)}\n",
      "x 982\n",
      "y 274\n",
      "{11: (1045, 332)}\n",
      "x 978\n",
      "y 276\n",
      "{11: (1042, 331)}\n",
      "x 974\n",
      "y 276\n",
      "{11: (1039, 329)}\n",
      "x 970\n",
      "y 276\n",
      "{11: (1038, 330)}\n",
      "x 970\n",
      "y 276\n",
      "{11: (1036, 331)}\n",
      "x 968\n",
      "y 278\n",
      "{11: (1034, 334)}\n",
      "x 966\n",
      "y 278\n",
      "{11: (1033, 336)}\n",
      "x 964\n",
      "y 278\n",
      "{11: (1030, 333)}\n",
      "x 962\n",
      "y 278\n",
      "{11: (1027, 333)}\n",
      "x 958\n",
      "y 279\n",
      "{11: (1025, 341)}\n",
      "x 956\n",
      "y 280\n",
      "{11: (1023, 341)}\n",
      "x 954\n",
      "y 280\n",
      "{11: (1022, 342)}\n",
      "x 952\n",
      "y 281\n",
      "{11: (1020, 343)}\n",
      "x 950\n",
      "y 282\n",
      "{11: (1017, 344)}\n",
      "x 946\n",
      "y 282\n",
      "{11: (1015, 344)}\n",
      "x 944\n",
      "y 282\n",
      "{11: (1013, 349)}\n",
      "x 942\n",
      "y 284\n",
      "{11: (1010, 349)}\n",
      "x 938\n",
      "y 284\n",
      "{11: (1008, 348)}\n",
      "x 936\n",
      "y 284\n",
      "{11: (1006, 349)}\n",
      "x 934\n",
      "y 285\n",
      "{11: (1003, 349)}\n",
      "x 930\n",
      "y 286\n",
      "{11: (1001, 352)}\n",
      "x 928\n",
      "y 286\n",
      "{11: (997, 364)}\n",
      "x 924\n",
      "y 287\n",
      "{11: (996, 355)}\n",
      "x 922\n",
      "y 288\n",
      "{11: (994, 355)}\n",
      "x 919\n",
      "y 288\n",
      "{11: (992, 355)}\n",
      "x 914\n",
      "y 288\n",
      "{11: (991, 356)}\n",
      "x 912\n",
      "y 289\n",
      "{11: (989, 370)}\n",
      "x 910\n",
      "y 290\n",
      "{11: (988, 359)}\n",
      "x 907\n",
      "y 290\n",
      "{11: (986, 359)}\n",
      "x 904\n",
      "y 292\n",
      "{11: (985, 360)}\n",
      "x 902\n",
      "y 292\n",
      "{11: (981, 359)}\n",
      "x 898\n",
      "y 292\n",
      "{11: (979, 363)}\n",
      "x 895\n",
      "y 294\n",
      "{11: (974, 363)}\n",
      "x 887\n",
      "y 294\n",
      "{11: (973, 363)}\n",
      "x 887\n",
      "y 294\n",
      "{11: (971, 363)}\n",
      "x 886\n",
      "y 295\n",
      "{11: (968, 364)}\n",
      "x 881\n",
      "y 296\n",
      "{11: (965, 362)}\n",
      "x 878\n",
      "y 296\n",
      "{11: (963, 363)}\n",
      "x 876\n",
      "y 298\n",
      "{11: (961, 361)}\n",
      "x 873\n",
      "y 298\n",
      "{11: (942, 361)}\n",
      "x 834\n",
      "y 298\n",
      "{11: (929, 363)}\n",
      "x 834\n",
      "y 300\n",
      "{11: (926, 364)}\n",
      "x 833\n",
      "y 300\n",
      "{11: (920, 365)}\n",
      "x 822\n",
      "y 300\n",
      "{11: (916, 365)}\n",
      "x 819\n",
      "y 300\n",
      "{11: (915, 375)}\n",
      "x 819\n",
      "y 302\n",
      "{11: (913, 375)}\n",
      "x 819\n",
      "y 302\n",
      "{11: (912, 379)}\n",
      "x 819\n",
      "y 304\n",
      "{11: (909, 376)}\n",
      "x 817\n",
      "y 303\n",
      "{11: (905, 380)}\n",
      "x 811\n",
      "y 304\n",
      "{11: (903, 379)}\n",
      "x 811\n",
      "y 306\n",
      "{11: (898, 380)}\n",
      "x 802\n",
      "y 306\n",
      "{11: (896, 382)}\n",
      "x 801\n",
      "y 308\n",
      "{11: (902, 382)}\n",
      "x 817\n",
      "y 308\n",
      "{11: (897, 384)}\n",
      "x 811\n",
      "y 308\n",
      "{11: (893, 383)}\n",
      "x 807\n",
      "y 309\n",
      "{11: (888, 387)}\n",
      "x 799\n",
      "y 310\n",
      "{11: (886, 389)}\n",
      "x 798\n",
      "y 309\n",
      "{11: (881, 396)}\n",
      "x 793\n",
      "y 312\n"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\henri\\OneDrive\\Desktop\\DTU courses\\31392 Perception\\Final project\\tracking\\hcontrack.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=9'>10</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=10'>11</a>\u001b[0m     height, width, _ \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39;49mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=12'>13</a>\u001b[0m     \u001b[39m# Extract Region of interest\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=13'>14</a>\u001b[0m     \u001b[39m#frame = frame[300:900,400:1150]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/Final%20project/tracking/hcontrack.ipynb#ch0000001?line=14'>15</a>\u001b[0m     rotated \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mrotate_bound(frame, \u001b[39m15\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
>>>>>>> 6cc8745b1ee30cbcf8d5d9cef0a011acd7749d70
     ]
    }
   ],
   "source": [
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
<<<<<<< HEAD
    "cap = cv2.VideoCapture(\"video/Stereo conveyor without occlusions.mp4\")\n",
=======
    "cap = cv2.VideoCapture(\"Stereo conveyor without occlusions.mp4\")\n",
>>>>>>> 6cc8745b1ee30cbcf8d5d9cef0a011acd7749d70
    "\n",
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Extract Region of interest\n",
    "    #frame = frame[300:900,400:1150]\n",
    "    rotated = imutils.rotate_bound(frame, 15)\n",
    "    rotated2=rotated[450:800,350:1250]\n",
    "    roi = imutils.rotate_bound(rotated2, -15)\n",
    "    \n",
    "    #hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #hsv_channels = cv2.split(hsv)\n",
    "    #rows = frame.shape[0]\n",
    "    #cols = frame.shape[1]\n",
    "\n",
    "    #for i in range(0, rows):\n",
    "    #    for j in range(0, cols):\n",
    "    #        h = hsv_channels[0][i][j]\n",
    "    #        if h > 90 and h < 130:\n",
    "    #            hsv_channels[2][i][j] = 255\n",
    "    #        else:\n",
    "    #            hsv_channels[2][i][j] = 0\n",
    "    #roi=hsv_channels[2]\n",
    "\n",
    "    # 1. Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "    _, mask = cv2.threshold(mask, 20, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.dilate(mask, None, iterations=6)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "\n",
    "    biggest_area=0\n",
    "    best_cnt = None\n",
    "    for cnt in contours:\n",
    "        # Calculate area and remove small elements\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>biggest_area:\n",
    "            biggest_area=area\n",
    "            best_cnt = cnt\n",
    "    if biggest_area>2000:\n",
    "        x, y, w, h = cv2.boundingRect(best_cnt)\n",
    "        detections.append([x, y, w, h])\n",
<<<<<<< HEAD
    "        # 2. Object Tracking\n",
    "        boxes_ids = tracker.update(detections)\n",
    "        print('x',x)\n",
    "        print('y',y)\n",
    "        for box_id in boxes_ids:\n",
    "            if (x>0 and x<1200)and(y>200 and y<730):\n",
    "                x, y, w, h, id = box_id\n",
    "                rx=x-25\n",
    "                ry=y-25\n",
    "                rw=w+50\n",
    "                rh=h+50\n",
    "                centerx=(rx+rx+rw)//2\n",
    "                centery=(ry+ry+rh)//2\n",
    "                c=cv2.rectangle(roi, (rx, ry), (rx + rw, ry + rh), (0, 255, 0), 3)\n",
    "                cv2.circle(roi,(centerx,centery),5,(0,0,255), -1)  \n",
    "                cv2.rectangle(frame, (rx, ry), (rx + rw, ry + rh), (0, 255, 0), 3)\n",
    "                cv2.circle(frame,(centerx,centery),5,(0,0,255), -1)      \n",
    "                if x>0 and y>0:\n",
    "                    crop_img = roi[y:y+h, x:x+w]\n",
    "                    ncrop_img=cv2.resize(crop_img, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "                    k+=1\n",
    "                    cv2.imwrite('video_crop/'+str(k)+'.jpg', ncrop_img)\n",
=======
    "    # 2. Object Tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        x=x-25\n",
    "        y=y-25\n",
    "        w=w+50\n",
    "        h=h+50\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        #cv2.rectangle(mask, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
>>>>>>> 6cc8745b1ee30cbcf8d5d9cef0a011acd7749d70
    "\n",
    "    cv2.imshow(\"roi\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", thresh)\n",
    "\n",
<<<<<<< HEAD
    "    #key = cv2.waitKey(25) # can be removed \n",
=======
    "    key = cv2.waitKey(30)\n",
>>>>>>> 6cc8745b1ee30cbcf8d5d9cef0a011acd7749d70
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # q will end the program\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 1\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"Stereo conveyor without occlusions.mp4\")\n",
    "ret, frame = cap.read()\n",
    "firstFrame = None\n",
    "while ret:\n",
    "    #Detecting movement\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    rotated = imutils.rotate_bound(gray, 15)\n",
    "    rotated2=rotated[450:800,350:1250]\n",
    "    roi = imutils.rotate_bound(rotated2, -15)\n",
    "    if firstFrame is None:\n",
    "        firstFrame = roi\n",
    "        continue\n",
    "\n",
    "    feat1 = cv2.goodFeaturesToTrack(roi, maxCorners=1000, qualityLevel=0.4, minDistance=10)\n",
    "    feat2, status, error = cv2.calcOpticalFlowPyrLK(roi, firstFrame, feat1, None)\n",
    "\n",
    "    for i in range(len(feat1)):\n",
    "        f10=int(feat1[i][0][0])\n",
    "        f11=int(feat1[i][0][1])\n",
    "        f20=int(feat2[i][0][0])\n",
    "        f21=int(feat2[i][0][1])\n",
    "        #cv2.circle(frame, (f10, f11), 5, (0, 255, 0), -1)\n",
    "        #cv2.line(frame, (f10,f11), (f20, f21), (0, 255, 0), 2)\n",
    "\n",
    "        if ((abs(f10-f20))/(f10+f20) >= 0.05) or ((abs(f11-f21))/(f11+f21) >= 0.05): # 0.005\n",
    "            \n",
    "            #cv2.line(frame, (f10,f11), (f20, f21), (0, 255, 0), 2)\n",
    "            cv2.circle(roi, (f10, f11), 5, (0, 255, 0), -1)\n",
    "    cv2.imshow('image', roi)\n",
    "    cv2.waitKey\n",
    "    \n",
    "    #firstFrame = gray\n",
    "    ret, frame = cap.read()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dba4e39bde81d51a0d9c8c6f450212468c51e66449dcd8bec1436e8ac13e18af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
