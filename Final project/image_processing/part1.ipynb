{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of stereo camera\n",
    "- Basically recycling Week 4 code\n",
    "- link to get images: https://campuscvut-my.sharepoint.com/:f:/g/personal/maleklu6_cvut_cz/EnyU2LTN6QFOlGlts1-sSusB6t9Q6hAcSeDAQd2se_cJlQ?e=gff67m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "* change parameters here to adjust the path and part of codes that are executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_calibration = False           # Already calibrated, could remain False\n",
    "rerun_undistortion = False          # Undistorts images defined in path\n",
    "rerun_rectification = False          # Rectify images in path\n",
    "rerun_rect_uncalib = True           # Rectify images in path\n",
    "rerun_depth = True                  # Create disparity map from rectified images\n",
    "path_calib = 'images/calibration/original/'\n",
    "path_dist_in = 'images/sample_without_occlusion/original/'\n",
    "path_dist_out = 'images/sample_without_occlusion/undistorted/'\n",
    "path_rect_in = 'images/sample_without_occlusion/original/'\n",
    "path_rect_out = 'images/sample_without_occlusion/rectified/'\n",
    "path_rect_uncalib_out = 'images/sample_without_occlusion/rectified_uncalibrated/'\n",
    "path_depth_in = 'images/sample_without_occlusion/rectified/'\n",
    "path_depth_out = 'images/sample_without_occlusion/depth/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "* Values from previous runs. Used if rerun_calib is set to false (needed in the next part)\n",
    "* No need to run the calibratino again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_left = np.array([[590.24505615, 0, 723.85543853], [\n",
    "                  0, 700.56091309, 369.43859036], [0, 0, 1]])\n",
    "K_right = np.array([[698.72259521, 0, 648.50704794], [\n",
    "                   0, 698.6318967, 374.0875587], [0, 0, 1]])\n",
    "dist_left = np.array([[-3.29479763e-01, 1.41779367e-01, -\n",
    "                      1.15867147e-04, 2.53566722e-04, -3.10092346e-02]])\n",
    "dist_right = np.array([[-3.25580109e-01, 1.39151479e-01, -\n",
    "                     2.55229666e-04, 4.20203965e-04, -3.19659112e-02]])\n",
    "mtx_left = np.array([[701.57106384,0,620.1497902],[0,701.53525002,369.95242304],[0,0,1]])\n",
    "mtx_right = np.array([[699.26893071,0,649.01413957],[0,699.60352684,374.60780826],[0,0,1]])\n",
    "roi = (0, 0, 1279, 719)\n",
    "R = np.array([[0.98609477,-0.01017771,0.16587198],[0.01153576,0.99990735,-0.00722601],[-0.16578306,0.00903899,0.98612082]])\n",
    "T = np.array([[-3.62890477],[ 0.00624134],[ 1.85263231]])\n",
    "E = np.array([[-0.02240624,-1.85240425,0.01954185],[ 1.22526008, 0.01394609,3.88583833],[-0.04801674,-3.62850504, 0.02518724]])\n",
    "F = np.array([[ 2.41550145e-07,1.68252147e-05,-6.51507831e-03], [-1.32106155e-05,-1.26687471e-07,-1.51199226e-02],[5.14696937e-03,1.21641825e-02,1.00000000e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(debug):\n",
    "\n",
    "    # Write the image names\n",
    "    images_left = glob.glob(path_calib+'left-*.png')\n",
    "    images_right = glob.glob(path_calib+'right-*.png')\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "\n",
    "    # Implement the number of vertical and horizontal corners\n",
    "    nb_vertical = 9\n",
    "    nb_horizontal = 6\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nb_horizontal*nb_vertical, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nb_vertical, 0:nb_horizontal].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints_left = []  # 2d points in image plane.\n",
    "    imgpoints_right = []  # 2d points in image plane.\n",
    "\n",
    "    for i in range(0,len(images_left)):\n",
    "\n",
    "        # Load the image\n",
    "        gray_left = cv2.cvtColor(cv2.imread(images_left[i]), cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(cv2.imread(images_right[i]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Implement findChessboardCorners here\n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left, (nb_vertical, nb_horizontal))\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right, (nb_vertical, nb_horizontal))\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right==True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints_left.append(corners_left)\n",
    "            imgpoints_right.append(corners_right)\n",
    "\n",
    "    # Get the camera matrix\n",
    "    _, mtx_left, dist_left, _, _ = cv2.calibrateCamera(objpoints, imgpoints_left, gray_left.shape[::-1], None, None)\n",
    "    _, mtx_right, dist_right, _, _ = cv2.calibrateCamera(objpoints, imgpoints_right, gray_right.shape[::-1], None, None)\n",
    "    K_left, roi_left = cv2.getOptimalNewCameraMatrix(mtx_left, dist_left, gray_left.shape[::-1], alpha=0)\n",
    "    K_right, roi_right = cv2.getOptimalNewCameraMatrix(mtx_right, dist_right, gray_left.shape[::-1], alpha=0)\n",
    "    _, K_left, dist_left, K_right, dist_right, R, T, E, F = cv2.stereoCalibrate(objpoints, imgpoints_left, imgpoints_right, K_left, dist_left, K_right, dist_right, gray_left.shape[::-1])\n",
    "\n",
    "    # Print calibrated values\n",
    "    if debug:\n",
    "        print('K_left', K_left)\n",
    "        print('K_right',K_right)\n",
    "        print('dist_left',dist_left)\n",
    "        print('dist_right',dist_right)\n",
    "        print('mtx_left',mtx_left)\n",
    "        print('mtx_right',mtx_right)\n",
    "        print('roi - same for both',roi)\n",
    "        print('R',R)\n",
    "        print('T',T)\n",
    "        print('E',E)\n",
    "        print('F',F)\n",
    "\n",
    "    return K_left, K_right, dist_left, dist_right, mtx_left, mtx_right, roi, objpoints, imgpoints_left, imgpoints_right, R, T, E, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_calibration:\n",
    "    K_left, K_right, dist_left, dist_right, mtx_left, mtx_right, roi, objpoints, imgpoints_left, imgpoints_right, R, T, E, F = calibration(debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDISTORTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(side,mtx,dist,K,roi):\n",
    "    if side == 'left':\n",
    "        path_in = path_dist_in+'left/*.png'\n",
    "        path_out = path_dist_out+'left/left-'\n",
    "    elif side == 'right':\n",
    "        path_in = path_dist_in+'right/*.png'\n",
    "        path_out = path_dist_out+'right/right-'\n",
    "\n",
    "    images = glob.glob(path_in)\n",
    "    assert images\n",
    "\n",
    "    i = 0\n",
    "    for fname in images:\n",
    "        # undistort\n",
    "        img = cv2.imread(fname)\n",
    "        dst = cv2.undistort(img, mtx, dist, None, K)\n",
    "\n",
    "        # crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "        # save image\n",
    "        cv2.imwrite(path_out+str(i)+'.png', dst)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Undistortion \"+side+ \" done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_undistortion:\n",
    "    undistort('left',mtx_left,dist_left,K_left, roi)\n",
    "    undistort('right',mtx_right,dist_right,K_right, roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    (r, c) = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "def draw_epipolar_lines(gray_left, gray_right):\n",
    "    '''Draws epipolar lines to the image'''\n",
    "    # Create a sift detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    kp_left, des_left = sift.detectAndCompute(gray_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(gray_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    # Get fundamental matrix\n",
    "    F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC)\n",
    "\n",
    "    # Remove outliers\n",
    "    pts1 = pts1[inliers.ravel() == 1]\n",
    "    pts2 = pts2[inliers.ravel() == 1]\n",
    "\n",
    "    # Draw lines\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    epilines_left, keypoints_left = draw_lines(gray_left, gray_right, lines1, pts1, pts2)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    epilines_right, keypoints_right = draw_lines(gray_right, gray_left, lines2, pts2, pts1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 10))\n",
    "    axs[0].imshow(epilines_left)\n",
    "    axs[0].set_title('left epipolar lines')\n",
    "    axs[1].imshow(epilines_right)\n",
    "    axs[1].set_title('right epipolar lines')\n",
    "    plt.show()\n",
    "\n",
    "def rectify(img_left, img_right, K_left, dist_left, K_right, dist_right, R, T, E, F,debug=False):\n",
    "    '''\n",
    "    Function that we used in project week 4, but the rectification is incorrect\n",
    "    '''\n",
    "\n",
    "    # Change to grayscale\n",
    "    \n",
    "    #F,_,_= draw_epipolar_lines(gray_left, gray_right, debug)\n",
    "\n",
    "    # Find projection essential matrix E\n",
    "    #E = K_left.T@F@K_right\n",
    "    #R_right, _, t_right = cv2.decomposeEssentialMat(E)\n",
    "    # R_left = np.identity(3)\n",
    "    # t_left = np.zeros(shape=(3,1))\n",
    "    # P_left = np.hstack((K_left@R_left, K_left@t_left))\n",
    "    # P_right = np.hstack((K_right@R_right, K_right@t_right))\n",
    "\n",
    "    \n",
    "    R_left, R_right, P_left, P_right, Q, roi_left, roi_right = cv2.stereoRectify(K_left, dist_left, K_right, dist_right, gray_left.shape[::-1], R,T,flags=cv2.CALIB_ZERO_DISPARITY,alpha=0)\n",
    "    #TODO: Look at Q: disparity to depth matching matrix\n",
    "    \n",
    "    # Rectify images\n",
    "    leftMapX, leftMapY = cv2.initUndistortRectifyMap(K_left, dist_left, R_left, P_left, gray_left.shape[::-1], cv2.CV_32FC1)\n",
    "    left_rectified = cv2.remap(gray_left, leftMapX, leftMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "    rightMapX, rightMapY = cv2.initUndistortRectifyMap(K_right, dist_right, R_right, P_right, gray_left.shape[::-1], cv2.CV_32FC1)\n",
    "    right_rectified = cv2.remap(gray_right, rightMapX, rightMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified, right_rectified\n",
    "\n",
    "def rectify_uncalibrated(img_left, img_right, debug=False):\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    kp_left, des_left = sift.detectAndCompute(img_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    # Get fundamental matrix\n",
    "    F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC)\n",
    "\n",
    "    h1, w1 = img_left.shape\n",
    "    h2, w2 = img_right.shape\n",
    "    _, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, imgSize=(w1, h1))\n",
    "    \n",
    "    # Rectify images and save them\n",
    "    left_rectified = cv2.warpPerspective(img_left, H1, (w1, h1))\n",
    "    right_rectified = cv2.warpPerspective(img_right, H2, (w2, h2))\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified,right_rectified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncalibrated Rectification done\n"
     ]
    }
   ],
   "source": [
    "if rerun_rectification:\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_rect_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_rect_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Create a sift detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    for i in range(0, len(imagesL)):\n",
    "        gray_left = cv2.cvtColor(cv2.imread(imagesL[i]), cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(cv2.imread(imagesR[i]), cv2.COLOR_BGR2GRAY)\n",
    "        left_rectified, right_rectified = rectify(gray_left, gray_right, K_left, dist_left, K_right, dist_right, R, T, E, F, debug=False) \n",
    "\n",
    "        # Save images into folder\n",
    "        cv2.imwrite(path_rect_out+'left/left-'+str(i)+'.png', left_rectified)\n",
    "        cv2.imwrite(path_rect_out+'right/right-'+str(i)+'.png', right_rectified)\n",
    "    print(\"Calibrated Rectification done\")\n",
    "\n",
    "if rerun_rect_uncalib:\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_rect_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_rect_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Create a sift detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    for i in range(0, len(imagesL)):\n",
    "        gray_left = cv2.cvtColor(cv2.imread(imagesL[i]), cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(cv2.imread(imagesR[i]), cv2.COLOR_BGR2GRAY)\n",
    "        left_rectified, right_rectified = rectify_uncalibrated(gray_left, gray_right, debug=False) \n",
    "\n",
    "        # Save images into folder\n",
    "        cv2.imwrite(path_rect_uncalib_out+'left/left-'+str(i)+'.png', left_rectified)\n",
    "        cv2.imwrite(path_rect_uncalib_out+'right/right-'+str(i)+'.png', right_rectified)\n",
    "    print(\"Uncalibrated Rectification done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map(debug):\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_depth_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_depth_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Iterate through the images\n",
    "    for i in range(0, len(imagesL)):\n",
    "        img_left = cv2.imread(path_depth_in+'left/left-'+str(i)+'.png')\n",
    "        img_right = cv2.imread(path_depth_in+'right/right-'+str(i)+'.png')\n",
    "        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if debug:\n",
    "            f, (ax_left, ax_right) = plt.subplots(1, 2, figsize=(18, 18))\n",
    "            ax_left.imshow(gray_left,cmap='gray')\n",
    "            ax_right.imshow(gray_right,cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        min_disp = 7  # 7\n",
    "        num_disp = 3*16  # 3*16\n",
    "        block_size = 9  # 5, 11\n",
    "        stereo = cv2.StereoBM_create(numDisparities=num_disp, blockSize=block_size)\n",
    "        stereo.setMinDisparity(min_disp)\n",
    "        stereo.setDisp12MaxDiff(200)  # 200\n",
    "        stereo.setUniquenessRatio(1)  # 1\n",
    "        stereo.setSpeckleRange(10)  # 3\n",
    "        stereo.setSpeckleWindowSize(1)  # 3\n",
    "        disp = stereo.compute(gray_left, gray_right).astype(np.float32) / 16.0\n",
    "\n",
    "        # Save image\n",
    "        cv2.imwrite(path_depth_out+'img-'+str(i)+'.png', disp)\n",
    "\n",
    "        if debug:\n",
    "            f, (ax_left, ax_middle, ax_right) = plt.subplots(1, 3, figsize=(18, 18))\n",
    "            ax_left.imshow(gray_left,cmap='gray')\n",
    "            ax_middle.imshow(gray_right,cmap='gray')\n",
    "            ax_right.imshow(disp,cmap='gray')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_depth:\n",
    "    depth_map(debug=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b633d7eae87b5fed5bf766898b0c683375244dd1706eb915bb836f7448798b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
