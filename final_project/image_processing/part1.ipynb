{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of stereo camera\n",
    "- Basically recycling Week 4 code\n",
    "- link to get images: https://campuscvut-my.sharepoint.com/:f:/g/personal/maleklu6_cvut_cz/EnyU2LTN6QFOlGlts1-sSusB6t9Q6hAcSeDAQd2se_cJlQ?e=gff67m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "* change parameters here to adjust the path and part of codes that are executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_calibration = False           # Already calibrated, could remain False\n",
    "rerun_undistortion = False          # Undistorts images defined in path\n",
    "rerun_rectification = True          # Rectify images in path\n",
    "rerun_rect_uncalib = False        # Rectify images in path\n",
    "rerun_depth = False                  # Create disparity map from rectified images\n",
    "path_calib = 'images/calibration/original/'\n",
    "path_dist_in = 'images/sample_without_occlusion/original/'\n",
    "path_dist_out = 'images/sample_without_occlusion/undistorted/'\n",
    "path_rect_in = 'images/sample_without_occlusion/original/' #undistorted images should be used for uncalibrated rectification\n",
    "path_rect_out = 'images/sample_without_occlusion/rectified/'\n",
    "path_rect_uncalib_out = 'images/sample_without_occlusion/rectified_uncalibrated/'\n",
    "path_depth_in = 'images/sample_without_occlusion/rectified/'\n",
    "path_depth_out = 'images/sample_without_occlusion/depth/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALIBRATION\n",
    "* Values from previous runs. Used if rerun_calib is set to false (needed in the next part)\n",
    "* No need to run the calibratino again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_left = np.array([[705.12855386,   0,         621.0422932 ],\n",
    " [  0 ,        705.05638672, 370.57066306],\n",
    " [  0  ,         0      ,     1  ,      ]])\n",
    "K_right = np.array([[702.64805575  , 0     ,    649.52345869],\n",
    " [  0       ,  702.90821064, 373.12894423],\n",
    " [  0      ,     0       ,    1        ]])\n",
    "dist_left = np.array([[-3.29479779e-01 , 1.41779399e-01 ,-1.15869227e-04 , 2.53564192e-04\n",
    "  -3.10092442e-02]])\n",
    "dist_right = np.array([[-3.25580130e-01 , 1.39151531e-01 ,-2.55232895e-04 , 4.20204047e-04\n",
    "  -3.19659396e-02]])\n",
    "R = np.array([[ 0.99991381, -0.00530365, -0.01201018],\n",
    " [ 0.00527804 , 0.99998373, -0.00216356],\n",
    " [ 0.01202145 , 0.00209999 , 0.99992553]])\n",
    "T = np.array([[-1.19993826e+02],\n",
    " [-2.56957545e-01],\n",
    " [-5.18613288e-02]])\n",
    "F = np.array([[-6.02253356e-09 ,1.09798538e-07 ,-4.24691775e-04],\n",
    " [ 2.97380893e-06 , 5.39499206e-07 , 1.78876466e-01],\n",
    " [-1.67147433e-03 ,-1.80656239e-01 , 1.00000000e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(debug):\n",
    "\n",
    "    # Write the image names\n",
    "    images_left = glob.glob(path_calib+'left-*.png')\n",
    "    images_right = glob.glob(path_calib+'right-*.png')\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "\n",
    "    # Implement the number of vertical and horizontal corners\n",
    "    nb_vertical = 9\n",
    "    nb_horizontal = 6\n",
    "    checker_size = 33.6 # size of square in mm\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nb_horizontal*nb_vertical, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nb_vertical, 0:nb_horizontal].T.reshape(-1, 2)\n",
    "    objp *= checker_size #results in transformation T in mm units in real world\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints_left = []  # 2d points in image plane.\n",
    "    imgpoints_right = []  # 2d points in image plane.\n",
    "\n",
    "    for i in range(0,len(images_left)):\n",
    "\n",
    "        # Load the image\n",
    "        gray_left = cv2.cvtColor(cv2.imread(images_left[i]), cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(cv2.imread(images_right[i]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Implement findChessboardCorners here\n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left, (nb_vertical, nb_horizontal))\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right, (nb_vertical, nb_horizontal))\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right==True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints_left.append(corners_left)\n",
    "            imgpoints_right.append(corners_right)\n",
    "\n",
    "    # Get the camera matrix\n",
    "    _, K_left, dist_left, _, _ = cv2.calibrateCamera(objpoints, imgpoints_left, gray_left.shape[::-1], None, None)\n",
    "    _, K_right, dist_right, _, _ = cv2.calibrateCamera(objpoints, imgpoints_right, gray_right.shape[::-1], None, None)\n",
    "\n",
    "    # Get the excentric parameters between stereo lenses\n",
    "    '''Camera matrix output and distortion is the same as input'''\n",
    "    _, _, _, _, _, R, T, _, F = cv2.stereoCalibrate(objpoints, imgpoints_left, imgpoints_right, K_left, dist_left, K_right, dist_right, gray_left.shape[::-1], None, None, None, None, cv2.CALIB_RATIONAL_MODEL)\n",
    "\n",
    "    # Print calibrated values\n",
    "    if debug:\n",
    "        print('K_left',K_left)\n",
    "        print('K_right',K_right)\n",
    "        print('dist_left',dist_left)\n",
    "        print('dist_right',dist_right)\n",
    "        print('R',R)\n",
    "        print('T',T)\n",
    "        print('F', F)\n",
    "    return K_left, K_right, dist_left, dist_right, R, T, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_calibration:\n",
    "    K_left, K_right, dist_left, dist_right, R, T, F = calibration(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDISTORTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(side,K,dist):\n",
    "    if side == 'left':\n",
    "        path_in = path_dist_in+'left/*.png'\n",
    "        path_out = path_dist_out+'left/left-'\n",
    "    elif side == 'right':\n",
    "        path_in = path_dist_in+'right/*.png'\n",
    "        path_out = path_dist_out+'right/right-'\n",
    "\n",
    "    images = glob.glob(path_in)\n",
    "    assert images\n",
    "\n",
    "    # Get optimal intrinsic matrix based on parameter alpha (used for rectification?)\n",
    "    '''if alpha>0, the undistorted result is likely to have some black pixels corresponding to \"virtual\" pixels outside of the captured distorted image'''\n",
    "    (h,w) = cv2.imread(images[0]).shape[0:2]\n",
    "    K_new, roi = cv2.getOptimalNewCameraMatrix(K, dist,(w,h), alpha=0)\n",
    "    \n",
    "    i = 0\n",
    "    for fname in images:\n",
    "        # Undistort\n",
    "        img = cv2.imread(fname)\n",
    "        dst = cv2.undistort(img, K, dist, None, K_new)\n",
    "\n",
    "        # Crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "        # Save image\n",
    "        cv2.imwrite(path_out+str(i)+'.png', dst)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Undistortion \"+side+ \" done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_undistortion:\n",
    "    undistort('left',K_left,dist_left)\n",
    "    undistort('right',K_right,dist_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    (r, c) = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "def draw_epipolar_lines(img_left, img_right):\n",
    "    '''Draws epipolar lines to the image'''\n",
    "    \n",
    "    # Change to RGB\n",
    "    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_left, des_left = sift.detectAndCompute(gray_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(gray_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    # Get fundamental matrix\n",
    "    F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC)\n",
    "\n",
    "    # Remove outliers\n",
    "    pts1 = pts1[inliers.ravel() == 1]\n",
    "    pts2 = pts2[inliers.ravel() == 1]\n",
    "\n",
    "    # Draw lines\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    epilines_left, keypoints_left = draw_lines(gray_left, gray_right, lines1, pts1, pts2)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    epilines_right, keypoints_right = draw_lines(gray_right, gray_left, lines2, pts2, pts1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 10))\n",
    "    axs[0].imshow(epilines_left)\n",
    "    axs[0].set_title('left epipolar lines')\n",
    "    axs[1].imshow(epilines_right)\n",
    "    axs[1].set_title('right epipolar lines')\n",
    "    plt.show()\n",
    "\n",
    "def rectify(img_left, img_right, K_left, dist_left, K_right, dist_right, R, T, leftMapX, leftMapY,rightMapX, rightMapY, debug=False):\n",
    "    '''Rectify the image'''\n",
    "\n",
    "    left_rectified = np.zeros(img_left.shape[:2], np.uint8)\n",
    "    right_rectified = np.zeros(img_right.shape[:2], np.uint8)\n",
    "    left_rectified = cv2.remap(img_left, leftMapX, leftMapY, cv2.INTER_LINEAR, left_rectified, cv2.BORDER_CONSTANT)\n",
    "    right_rectified = cv2.remap(img_right, rightMapX, rightMapY, cv2.INTER_LINEAR, right_rectified, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified, right_rectified\n",
    "\n",
    "def rectify_uncalibrated(img_left, img_right, F, debug=False):  \n",
    "    ''' We use the fundamental matrix from calibration. Since the camera is not moving, F should be the same as the one from calibration. If we compute F here, we of course get new F values, as we \"calibrate\" it on different iamges'''\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_left, des_left = sift.detectAndCompute(img_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    \n",
    "    # Rectify images\n",
    "    (h,w,_) = img_left.shape\n",
    "    _, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, (w,h))\n",
    "    left_rectified = cv2.warpPerspective(img_left, H1, (w,h))\n",
    "    right_rectified = cv2.warpPerspective(img_right, H2, (w,h))\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified,right_rectified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_rectification:\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_rect_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_rect_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Get the mapping matrix (nearly the same for all images, the differences are not that signifficant)\n",
    "    (h,w,_) = cv2.imread(imagesL[0]).shape\n",
    "    R_left, R_right, P_left, P_right, _, roi_left, roi_right = cv2.stereoRectify(K_left, dist_left, K_right, dist_right, (w,h), R,T, alpha=0) #0.22 # CALIB_ZERO_DISPARITY\n",
    "    #TODO: Unused mising paramter Q: disparity to depth matching matrix = after getting disparit map, we can call reprojectImageTo3D() and get the 3D model     \n",
    "    #TODO: Use last two parameter (roi_left, roi_right) to crop the image\n",
    "\n",
    "    #  Find the Maping Matrices\n",
    "    leftMapX, leftMapY = cv2.initUndistortRectifyMap(K_left, dist_left, R_left, P_left, (w,h), cv2.CV_32FC1)\n",
    "    rightMapX, rightMapY = cv2.initUndistortRectifyMap(K_right, dist_right, R_right, P_right, (w,h), cv2.CV_32FC1)\n",
    "\n",
    "    # print(leftMapX,leftMapY)\n",
    "    # print(rightMapX,rightMapY)\n",
    "\n",
    "    for i in range(0, len(imagesL)):\n",
    "        left_rectified, right_rectified = rectify(cv2.imread(imagesL[i]), cv2.imread(imagesR[i]), K_left, dist_left, K_right, dist_right, R, T, leftMapX, leftMapY,rightMapX, rightMapY, debug=False) \n",
    "\n",
    "        # Save images into folder\n",
    "        cv2.imwrite(path_rect_out+'left/left-'+str(i)+'.png', left_rectified)\n",
    "        cv2.imwrite(path_rect_out+'right/right-'+str(i)+'.png', right_rectified)\n",
    "    print(\"Calibrated Rectification done\")\n",
    "\n",
    "if rerun_rect_uncalib:\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_rect_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_rect_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    for i in range(0, len(imagesL)):\n",
    "        left_rectified, right_rectified = rectify_uncalibrated(cv2.imread(imagesL[i]), cv2.imread(imagesR[i]), F, debug=False) \n",
    "\n",
    "        # Save images into folder\n",
    "        cv2.imwrite(path_rect_uncalib_out+'left/left-'+str(i)+'.png', left_rectified)\n",
    "        cv2.imwrite(path_rect_uncalib_out+'right/right-'+str(i)+'.png', right_rectified)\n",
    "    print(\"Uncalibrated Rectification done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE DEPTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map(debug):\n",
    "\n",
    "    # Read the undistorted images\n",
    "    imagesL = glob.glob(path_depth_in+'left/*.png')\n",
    "    imagesR = glob.glob(path_depth_in+'right/*.png')\n",
    "    assert imagesL\n",
    "    assert imagesR\n",
    "\n",
    "    # Iterate through the images\n",
    "    for i in range(0, len(imagesL)):\n",
    "        img_left = cv2.imread(path_depth_in+'left/left-'+str(i)+'.png')\n",
    "        img_right = cv2.imread(path_depth_in+'right/right-'+str(i)+'.png')\n",
    "        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Parameters\n",
    "        min_disp = 0  # 22\n",
    "        num_disp = 16*14  # 256\n",
    "        block_size = 5  #5 \n",
    "        sigma = 7 #1.5\n",
    "        lmbda = 16000.0 #8000\n",
    "\n",
    "        # Disparity Map\n",
    "        stereo_left = cv2.StereoBM_create(numDisparities=num_disp, blockSize=block_size)\n",
    "        stereo_right = cv2.ximgproc.createRightMatcher(stereo_left)\n",
    "        stereo_left.setMinDisparity(min_disp)\n",
    "        stereo_left.setDisp12MaxDiff(1)  # 200\n",
    "        stereo_left.setUniquenessRatio(1)  # 1\n",
    "        stereo_left.setSpeckleRange(1)  # 10\n",
    "        stereo_left.setSpeckleWindowSize(1)  # 3\n",
    "        disp_left = stereo_left.compute(gray_left, gray_right)#.astype(np.float32)\n",
    "        disp_left2 = cv2.normalize(disp_left, None, 255, 0, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        disp_right = stereo_right.compute(gray_right,gray_left)\n",
    "\n",
    "        # WLSFilter\n",
    "        wls_filter = cv2.ximgproc.createDisparityWLSFilter(stereo_left)\n",
    "        wls_filter.setLambda(lmbda)\n",
    "        wls_filter.setSigmaColor(sigma)\n",
    "        disp_filtered = wls_filter.filter(disp_left, gray_left, disparity_map_right=disp_right)\n",
    "        disp_filtered[disp_filtered<-16] = -16\n",
    "        disp_filtered = (disp_filtered+16)/8\n",
    "\n",
    "        # Compute the Z coordinate\n",
    "        '''We look at the area around the centroid in depth image to get the Z coordinate'''\n",
    "        x = 1250\n",
    "        y = 360\n",
    "        Z = np.mean(disp_filtered[y-15:y+15,x-15:x+15]) # h,w format\n",
    "        \n",
    "        # Save image\n",
    "        cv2.imwrite(path_depth_out+'depth_filtered'+str(i)+'.png', disp_filtered)\n",
    "\n",
    "        if debug:\n",
    "            print(np.min(disp_filtered),np.max(disp_filtered),np.mean(disp_filtered))\n",
    "            f, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(30, 30))\n",
    "            ax1.imshow(gray_left,cmap='gray')\n",
    "            ax2.imshow(gray_right,cmap='gray')\n",
    "            ax3.imshow(disp_left,cmap='gray')\n",
    "            ax4.imshow(disp_left2,cmap='gray')\n",
    "            ax5.imshow(disp_right,cmap='gray')\n",
    "            ax6.imshow(disp_filtered,cmap='gray')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rerun_depth:\n",
    "    depth_map(debug=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b633d7eae87b5fed5bf766898b0c683375244dd1706eb915bb836f7448798b8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
