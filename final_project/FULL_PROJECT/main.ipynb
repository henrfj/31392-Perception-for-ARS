{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL PROJECT - depricated\n",
    "Here we will call all the other programs:\n",
    "\n",
    "The path will be in .gitignore it will be 3 folders in directory of this file:\n",
    "\n",
    "\n",
    "\"conveyor_sample_without\" is sample without occlusiosn, can be downloaded \n",
    "<a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2Fsample%5FStereo%5Fconveyor%5Fwithout%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>\n",
    "\n",
    "\"conveyor_full_without\" The whole conveyor belt dataset without occlusions downloaded <a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2FStereo%5Fconveyor%5Fwithout%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>\n",
    "\n",
    "\"conveyor_full_with\" Dataset conveyor with occlusions can be downloaded <a href=\"https://dtudk-my.sharepoint.com/personal/evanb_dtu_dk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject%2FStereo%5Fconveyor%5Fwith%5Focclusions%2Erar&parent=%2Fpersonal%2Fevanb%5Fdtu%5Fdk%2FDocuments%2FCourses%2F31392%2FFinal%5FProject&ga=1\">Here</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- include only necessary imports\n",
    "- optimize each function\n",
    "- create a video\n",
    "- write a report\n",
    "- if time, optimize compiler for this code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'also_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\henri\\OneDrive\\Desktop\\DTU courses\\31392 Perception\\final_project\\FULL_PROJECT\\main.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=22'>23</a>\u001b[0m \u001b[39m################# Initializations #################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=23'>24</a>\u001b[0m cnn_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mC:/Users/henri/OneDrive/Desktop/DTU courses/31392 Perception/final_project/FULL_PROJECT/cnn_model_3\u001b[39m\u001b[39m'\u001b[39m);\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=24'>25</a>\u001b[0m tracker \u001b[39m=\u001b[39m Kalman_tracker(occlusion\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, Verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, also_predict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, model\u001b[39m=\u001b[39;49mcnn_model, eligibility_trace\u001b[39m=\u001b[39;49m\u001b[39m0.75\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=27'>28</a>\u001b[0m \u001b[39m################### Main #######################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=28'>29</a>\u001b[0m \u001b[39m#path_left = \"conveyor_full_without/left/*.png\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=29'>30</a>\u001b[0m \u001b[39m#path_right = \"conveyor_full_without/right/*.png\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=30'>31</a>\u001b[0m \u001b[39m# path_left = \"conveyor_full_with/left/*.png\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=31'>32</a>\u001b[0m \u001b[39m# path_right = \"conveyor_full_with/right/*.png\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/henri/OneDrive/Desktop/DTU%20courses/31392%20Perception/final_project/FULL_PROJECT/main.ipynb#ch0000003?line=32'>33</a>\u001b[0m path_left \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Users/henri/OneDrive/Desktop/DTU courses/31392 Perception/final_project/tracking/video/full/with_occlusions/left/*.png\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'also_predict'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from kalman_tracker import Kalman_tracker\n",
    "from tensorflow import keras\n",
    "\n",
    "###################### for proper jupyter imports:\n",
    "#!pip install import-ipynb #install this before first run\n",
    "# import import_ipynb\n",
    "#note for myself: run with Python3.10 (not 64bit)\n",
    "#use the pythonian way:\n",
    "# from calibration import calibrate\n",
    "# from depth_map import compute_depth\n",
    "# from tracking import track\n",
    "# from neural_net import initialize_network, classify\n",
    "# or run with the following:\n",
    "#################################################\n",
    "\n",
    "%run calibration.ipynb #must be run, contains mandatory variables from calibration\n",
    "%run depth_map.ipynb\n",
    "create_output_video = False\n",
    "\n",
    "################# Initializations #################\n",
    "cnn_model = keras.models.load_model('C:/Users/henri/OneDrive/Desktop/DTU courses/31392 Perception/final_project/FULL_PROJECT/cnn_model_3');\n",
    "tracker = Kalman_tracker(occlusion=True, Verbose=False, also_predict=True, model=cnn_model, eligibility_trace=0.75)\n",
    "\n",
    "\n",
    "################### Main #######################\n",
    "path_left = \"conveyor_full_without/left/*.png\"\n",
    "path_right = \"conveyor_full_without/right/*.png\"\n",
    "# path_left = \"conveyor_full_with/left/*.png\"\n",
    "# path_right = \"conveyor_full_with/right/*.png\"\n",
    "\n",
    "images_left = glob.glob(path_left)\n",
    "assert images_left, \"No images found in {}\".format(path_left)\n",
    "images_right = glob.glob(path_right)\n",
    "assert images_right, \"No images found in {}\".format(path_right)\n",
    "\n",
    "# Create video\n",
    "if create_output_video:\n",
    "    img_buffer = []\n",
    "    FPS = 30 \n",
    "    out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), FPS, size)\n",
    "\n",
    "# MAIN\n",
    "no_of_frames = len(images_left)\n",
    "\n",
    "# GRAYSCALE\n",
    "gray_left = cv2.cvtColor(\n",
    "    cv2.imread(\"...png\"), cv2.COLOR_BGR2GRAY) # Add the first image without occlusion\n",
    "gray_right = cv2.cvtColor(\n",
    "    cv2.imread(\"...png\"), cv2.COLOR_BGR2GRAY) # Add the first image without occlusion\n",
    "depth_map = get_depth_map(gray_left, gray_right)\n",
    "\n",
    "\n",
    "for i in range(no_of_frames):\n",
    "    frame_left = cv2.imread(images_left[i])\n",
    "    frame_right = cv2.imread(images_right[i])\n",
    "\n",
    "    calibrated_left = calibrate(frame_left, frame_right)\n",
    "    track_frame, filtered, measured, prediction = tracker.next_frame(frame)\n",
    "    centroidx, centroidy = filtered[0], filtered[1]\n",
    "    z       = compute_depth(centroidx, centroidy, depth_map)\n",
    "\n",
    "    if z==0: # no depth\n",
    "        cv2.putText(track_frame, \"Depth: {}\".format(\"not available\"),\n",
    "                    (700, 600), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "    else: # Depth\n",
    "        cv2.putText(track_frame, \"Depth: {}\".format(str(z)),\n",
    "                    (700, 600), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "\n",
    "    if create_output_video:\n",
    "        img_buffer.append(frame_left)\n",
    "    \n",
    "    #Add more text to frame\n",
    "\n",
    "    cv2.imshow(\"Perception project\", track_frame) #roi\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #stop on q\n",
    "            break\n",
    "\n",
    "    print(\"\\rFrame {}/{}\".format(i+1, no_of_frames+1), end=\"\")\n",
    "\n",
    "# create_video(buffer)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\nSuccessfully completed\\nCreating video...\")\n",
    "if create_output_video:\n",
    "    for i in range(len(img_buffer)):\n",
    "        out.write(img_buffer[i])\n",
    "    out.release()\n",
    "    print(\"video created\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1902db9bb2e389c5c5f64e693209aef1412f369d132ca57a092e79ab8be655e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
