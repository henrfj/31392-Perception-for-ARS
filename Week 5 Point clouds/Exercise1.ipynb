{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration with RANSAC\n",
    "We are going to use open3d (http://www.open3d.org/) to handle  pointclouds and generation of pointclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "r2 = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "#draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be benefitial work on a downsampled version of the point cloud.\n",
    "you can use [```pointcloudname.voxel_down_sample()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html) where pointcloud is the name of your point cloud object.\n",
    "\n",
    "We also need to estimate the normals of the pointcloud points using [```pointcloudname.estimate_normals()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html)\n",
    "\n",
    "And finally find fpfh features or correspondance of the downsampled point clouds.\n",
    "[```o3d.pipelines.registration.compute_fpfh_feature()```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.compute_fpfh_feature.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "\n",
    "# 1 Downsample both point clouds\n",
    "r1.voxel_down_sample(voxel_size=voxel_size)\n",
    "r2.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "# 2 Estimate surface normals of pointclouds\n",
    "r1.estimate_normals()\n",
    "r2.estimate_normals()\n",
    "\n",
    "# 3 FPFH feature descriptor and correspondance on the downsampled pointcloud. \n",
    "# Raius used to describe a feature\n",
    "radius_feature = voxel_size * 2\n",
    "max_nn = 100\n",
    "registration_r1 = o3d.pipelines.registration.compute_fpfh_feature(r1,\n",
    " search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn))\n",
    "registration_r2 = o3d.pipelines.registration.compute_fpfh_feature(r2,\n",
    " search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac\n",
    "We will now attempt to use ransac to do a global registration of the two poinclouds.\n",
    "\n",
    "Using the function [```o3d.pipelines.registration.registration_ransac_based_on_feature_matching```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.registration_ransac_based_on_feature_matching.html) from open3d\n",
    "\n",
    "\n",
    "Try to find the transformation from r1 to r2.\n",
    "Attempt with point to point and point to plane\n",
    "```Python\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "```\n",
    "\n",
    "When using ransac focus on the arguments below the rest are optional\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Call RANSAC here\n",
    "####\n",
    "# We can try both point-to-point or point-to plane\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "\n",
    "source_sample = r1\n",
    "target_sample = r2\n",
    "source_fpfh = registration_r1\n",
    "target_fpfh = registration_r2\n",
    "distance_threshold = voxel_size*2 # change to 1\n",
    "\n",
    "ransac_result_r1_r2 = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample,\n",
    "    target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True, # mutual_filter\n",
    "    distance_threshold,\n",
    "    point_to_point, # point_to_point or point_to_plane\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draw_registrations(r1, r2, ransac_result_r1_r2.transformation, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Results r1 r2](Results/Ex1.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### A)\n",
    "    Can you get a decent transformation from r1 to r3?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "\n",
    "# 1 Downsample both point clouds\n",
    "r3.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "# 2 Estimate surface normals of pointclouds\n",
    "r3.estimate_normals()\n",
    "\n",
    "# 3 FPFH feature descriptor and correspondance on the downsampled pointcloud. \n",
    "# Raius used to describe a feature\n",
    "radius_feature = voxel_size * 2\n",
    "max_nn = 100\n",
    "registration_r3 = o3d.pipelines.registration.compute_fpfh_feature(r3,\n",
    " search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# RANSAC #\n",
    "##########\n",
    "# We can try both point-to-point or point-to plane\n",
    "point_to_point = o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "source_sample = r1\n",
    "target_sample = r3\n",
    "source_fpfh = registration_r1\n",
    "target_fpfh = registration_r3\n",
    "distance_threshold = voxel_size*2\n",
    "\n",
    "ransac_result_r1_r3 = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample,\n",
    "    target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True, # mutual_filter\n",
    "    distance_threshold,\n",
    "    point_to_point, # point_to_plane\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registrations(r1, r3, ransac_result_r1_r3.transformation, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result](Results/Ex1.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### B)\n",
    "    with the following checkers can you get better results from RANSAC? Try tweaking the parameters of them Can you make Point to Plane work do not spend too long on this if you cant skip it. (I was not able to get a good fit)\n",
    "\n",
    "You can also try tweaking the voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 2\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.95)\n",
    "\n",
    "checker_list = [c0,c1,c2]\n",
    "\n",
    "source_sample = r1\n",
    "target_sample = r3\n",
    "source_fpfh = registration_r1\n",
    "target_fpfh = registration_r3\n",
    "\n",
    "ransac_result_checkers = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registrations(r1, r3, ransac_result_checkers.transformation, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Last result](Results/Ex1.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
